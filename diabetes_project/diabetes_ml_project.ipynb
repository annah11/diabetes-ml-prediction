{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Prediction using Machine Learning\n",
    "\n",
    "This notebook implements multiple machine learning models to predict diabetes using the Pima Indians Diabetes Dataset.\n",
    "\n",
    "## Models Used:\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Naive Bayes\n",
    "- Random Forest\n",
    "\n",
    "## Dataset Features:\n",
    "- Pregnancies\n",
    "- Glucose\n",
    "- Blood Pressure\n",
    "- Skin Thickness\n",
    "- Insulin\n",
    "- BMI (Body Mass Index)\n",
    "- Diabetes Pedigree Function\n",
    "- Age\n",
    "- Outcome (Target Variable: 0 = No Diabetes, 1 = Diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(df['Outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeature scaling completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "knn_pred = knn_model.predict(X_test_scaled)\n",
    "knn_pred_proba = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"K-Nearest Neighbors Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, knn_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, knn_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, knn_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, knn_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_pred = nb_model.predict(X_test_scaled)\n",
    "nb_pred_proba = nb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, nb_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, nb_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, nb_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, nb_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, rf_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, rf_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "models = [\n",
    "    ('KNN', knn_pred),\n",
    "    ('Naive Bayes', nb_pred),\n",
    "    ('Random Forest', rf_pred)\n",
    "]\n",
    "\n",
    "for idx, (name, pred) in enumerate(models):\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{name} Confusion Matrix')\n",
    "    axes[idx].set_ylabel('True Label')\n",
    "    axes[idx].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Confusion matrices saved as 'confusion_matrices.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_proba = [\n",
    "    ('KNN', knn_pred_proba),\n",
    "    ('Naive Bayes', nb_pred_proba),\n",
    "    ('Random Forest', rf_pred_proba)\n",
    "]\n",
    "\n",
    "for name, pred_proba in models_proba:\n",
    "    fpr, tpr, _ = roc_curve(y_test, pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Model Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"ROC curves saved as 'roc_curves.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Feature Importance - Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Feature importance plot saved as 'feature_importance.png'\")\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison table\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Naive Bayes', 'Random Forest'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, knn_pred),\n",
    "        accuracy_score(y_test, nb_pred),\n",
    "        accuracy_score(y_test, rf_pred)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, knn_pred),\n",
    "        precision_score(y_test, nb_pred),\n",
    "        precision_score(y_test, rf_pred)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, knn_pred),\n",
    "        recall_score(y_test, nb_pred),\n",
    "        recall_score(y_test, rf_pred)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, knn_pred),\n",
    "        f1_score(y_test, nb_pred),\n",
    "        f1_score(y_test, rf_pred)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identify best model\n",
    "best_model_idx = results_df['Accuracy'].idxmax()\n",
    "best_model = results_df.loc[best_model_idx, 'Model']\n",
    "best_accuracy = results_df.loc[best_model_idx, 'Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model} with Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "1. All three models (KNN, Naive Bayes, Random Forest) were successfully trained and evaluated\n",
    "2. Feature importance analysis revealed the most significant predictors of diabetes\n",
    "3. ROC curves and AUC scores provide insights into model discrimination ability\n",
    "4. Confusion matrices show the distribution of true positives, true negatives, false positives, and false negatives\n",
    "\n",
    "### Next Steps:\n",
    "- Hyperparameter tuning to improve model performance\n",
    "- Cross-validation for more robust evaluation\n",
    "- Ensemble methods for potentially better results\n",
    "- Feature engineering to create new meaningful features\n",
    "- Handling class imbalance if present"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
